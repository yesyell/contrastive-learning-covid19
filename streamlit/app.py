import streamlit as st
import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
from scipy.io import wavfile
from io import BytesIO
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode
from audio import change_volume

# ì‹¤í—˜ ì™„ë£Œí•œ ëª¨ë¸ import
# from your_model_module import load_model, predict

st.title("ğŸ•µï¸ ë‹¹ì‹ ì˜ í˜¸í¡ìŒì€ ì½”ë¡œë‚˜ë¥¼ ì•Œê³ ìˆë‹¤!")
st.write('ì•ˆë…•í•˜ì„¸ìš”, ì €í¬ëŠ” 24su Medical AI ìŒíŒŒìŒíŒŒ íŒ€ ì…ë‹ˆë‹¤. ì €í¬ëŠ” ë©”íƒ€ë°ì´í„°ì™€ í˜¸í¡ìŒ ë°ì´í„°ë¥¼ ëŒ€ì¡°í•™ìŠµìœ¼ë¡œ ì½”ë¡œë‚˜ë¥¼ ë¶„ë¥˜í•˜ëŠ” í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.')
st.info('**<Demo Page ì‚¬ìš©ì„¤ëª…ì„œ>**'
        '\n 1. ì‚¬ìš©ìì˜ í˜¸í¡ìŒ ë…¹ìŒ'
        '\n     - START ì´í›„ í‘œì‹œë˜ëŠ” STOP ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í”„ë¡œì„¸ìŠ¤ ì „ì²´ê°€ ì¢…ë£Œë˜ë‹ˆ ì£¼ì˜í•´ ì£¼ì„¸ìš”!'
        '\n 2. í˜¸í¡ìŒì„ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ MFCCë¡œ ì‹œê°í™”'
        '\n 3. ì½”ë¡œë‚˜ ì˜ˆì¸¡ ğŸ©º'
        )
st.markdown('---')

st.subheader("ğŸ˜¤ í˜¸í¡ìŒì„ ë…¹ìŒí•´ ì£¼ì„¸ìš”!")

class AudioProcessor(AudioProcessorBase):
    def __init__(self):
        self.audio_data = []

    def recv_queued(self, frames):
        for frame in frames:
            self.audio_data.extend(frame.to_ndarray().flatten().tolist())
        return frames

    def get_audio_data(self):
        return np.array(self.audio_data, dtype=np.float32)

webrtc_ctx = webrtc_streamer(
    key="audio-recorder",
    mode=WebRtcMode.SENDRECV,
    audio_receiver_size=1024,
    media_stream_constraints={"video": False, "audio": True},
    audio_processor_factory=AudioProcessor,
    async_processing=True,
)

# ë…¹ìŒ ì¤‘ ìƒíƒœë¥¼ ë³´ì—¬ì£¼ëŠ” UI
if webrtc_ctx.state.playing:
    st.write("ğŸ™ï¸ë…¹ìŒ ì¤‘... ë§ˆì´í¬ì— ëŒ€ê³  ë§ì”€í•´ ì£¼ì„¸ìš”!")
    if webrtc_ctx.audio_processor:
        st.write(f"ë…¹ìŒëœ ìƒ˜í”Œ ìˆ˜: {len(webrtc_ctx.audio_processor.audio_data)}")

# ë…¹ìŒ ì¢…ë£Œ ë²„íŠ¼
if st.button("ë…¹ìŒ ì¢…ë£Œ ë° ë¶„ì„"):
    if webrtc_ctx.audio_processor and len(webrtc_ctx.audio_processor.audio_data) > 0:
        st.write("ğŸ‘¨â€ğŸ’¼ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬ ì¤‘...")
        st.markdown("---")

        audio_array = webrtc_ctx.audio_processor.get_audio_data()
        sample_rate = 48000  # WebRTCì˜ ì¼ë°˜ì ì¸ ìƒ˜í”Œë§ ë ˆì´íŠ¸

        # ì˜¤ë””ì˜¤ ë°ì´í„° ë³¼ë¥¨ ì¡°ì ˆ
        data_scaled = change_volume(audio_array)

        st.subheader("ğŸ’» MFCCë¡œ í‘œí˜„ëœ ë‹¹ì‹ ì˜ í˜¸í¡ìŒì€?")
        
        with st.container():
            with st.spinner('MFCCë¡œ í˜¸í¡ìŒì„ ë³€í™˜ ì¤‘ì— ìˆì–´ìš”...'):
                # MFCC ê³„ì‚°
                hop_length = 512
                mfccs = librosa.feature.mfcc(y=data_scaled, sr=sample_rate, n_mfcc=30)

                # MFCC ì‹œê°í™”
                plt.figure(figsize=(10, 5))
                librosa.display.specshow(mfccs, sr=sample_rate, hop_length=hop_length)
                
                # ì´ë¯¸ì§€ë¥¼ BytesIO ê°ì²´ë¡œ ì €ì¥
                buf = BytesIO()
                plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)
                buf.seek(0)
                
                st.image(buf, caption='MFCC Spectrogram', use_column_width=True)

                plt.close()  # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ë¥¼ ìœ„í•´ figure ë‹«ê¸°

        # ì˜¤ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ ë° ëª¨ë¸ ì˜ˆì¸¡
        col1, col2 = st.columns(2)
        
        with col1:
            # WAV íŒŒì¼ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ
            wav_file = BytesIO()
            wavfile.write(wav_file, sample_rate, audio_array)
            wav_file.seek(0)
            st.download_button(label="ğŸ“‚ í˜¸í¡ìŒ ë‹¤ìš´ë¡œë“œ", data=wav_file, file_name="respiratory_sounds.wav", mime="audio/wav")

        with col2:
            if st.button("ğŸ§‘â€âš•ï¸ í˜¸í¡ìŒ ì½”ë¡œë‚˜ ìƒíƒœ ì˜ˆì¸¡"):
                # ëª¨ë¸ ì˜ˆì¸¡ (ì˜ì‚¬ ì½”ë“œ)
                # model = load_model("path_to_your_model")
                # prediction = predict(model, mfccs)
                # with st.spinner('ë‹¹ì‹ ì˜ í˜¸í¡ìŒì„ ë¶„ì„í•˜ê³  ìˆì–´ìš”...'):
                #     time.sleep(2)
                # st.success(f"ì˜ˆì¸¡ ê²°ê³¼: {prediction}")

                st.success("ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì•„ë§ˆ ì´ì¯¤ì— ëœ°ê±°ì—ìš”!")
        
        # ì˜¤ë””ì˜¤ ë°ì´í„° ì´ˆê¸°í™”
        webrtc_ctx.audio_processor.audio_data.clear()
    else:
        st.write("ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.write("ë…¹ìŒì„ ì¢…ë£Œí•˜ê³  ë¶„ì„í•˜ë ¤ë©´ 'ë…¹ìŒ ì¢…ë£Œ ë° ë¶„ì„' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")